{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000000000000000000e+00</th>\n",
       "      <th>0.000000000000000000e+00.1</th>\n",
       "      <th>0.000000000000000000e+00.2</th>\n",
       "      <th>0.000000000000000000e+00.3</th>\n",
       "      <th>0.000000000000000000e+00.4</th>\n",
       "      <th>0.000000000000000000e+00.5</th>\n",
       "      <th>0.000000000000000000e+00.6</th>\n",
       "      <th>0.000000000000000000e+00.7</th>\n",
       "      <th>0.000000000000000000e+00.8</th>\n",
       "      <th>0.000000000000000000e+00.9</th>\n",
       "      <th>0.000000000000000000e+00.10</th>\n",
       "      <th>0.000000000000000000e+00.11</th>\n",
       "      <th>0.000000000000000000e+00.12</th>\n",
       "      <th>0.000000000000000000e+00.13</th>\n",
       "      <th>0.000000000000000000e+00.14</th>\n",
       "      <th>0.000000000000000000e+00.15</th>\n",
       "      <th>0.000000000000000000e+00.16</th>\n",
       "      <th>0.000000000000000000e+00.17</th>\n",
       "      <th>0.000000000000000000e+00.18</th>\n",
       "      <th>4.200000000000000000e+01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2577.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>3170.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4442.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>1667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14571 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.000000000000000000e+00  0.000000000000000000e+00.1  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "...                         ...                         ...   \n",
       "14566                       0.0                         0.0   \n",
       "14567                       0.0                         0.0   \n",
       "14568                       0.0                         0.0   \n",
       "14569                       0.0                         0.0   \n",
       "14570                       0.0                         0.0   \n",
       "\n",
       "       0.000000000000000000e+00.2  0.000000000000000000e+00.3  \\\n",
       "0                             0.0                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             0.0                         0.0   \n",
       "4                             0.0                         0.0   \n",
       "...                           ...                         ...   \n",
       "14566                         0.0                         0.0   \n",
       "14567                         0.0                         0.0   \n",
       "14568                         0.0                         0.0   \n",
       "14569                         0.0                         0.0   \n",
       "14570                         0.0                         0.0   \n",
       "\n",
       "       0.000000000000000000e+00.4  0.000000000000000000e+00.5  \\\n",
       "0                             0.0                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             0.0                         0.0   \n",
       "4                             0.0                         0.0   \n",
       "...                           ...                         ...   \n",
       "14566                         0.0                         0.0   \n",
       "14567                         0.0                         0.0   \n",
       "14568                         0.0                         0.0   \n",
       "14569                         0.0                         0.0   \n",
       "14570                         0.0                         0.0   \n",
       "\n",
       "       0.000000000000000000e+00.6  0.000000000000000000e+00.7  \\\n",
       "0                             0.0                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             0.0                         0.0   \n",
       "4                             0.0                         0.0   \n",
       "...                           ...                         ...   \n",
       "14566                         0.0                         0.0   \n",
       "14567                        45.0                        49.0   \n",
       "14568                         0.0                         0.0   \n",
       "14569                         0.0                         0.0   \n",
       "14570                         0.0                         0.0   \n",
       "\n",
       "       0.000000000000000000e+00.8  0.000000000000000000e+00.9  \\\n",
       "0                             0.0                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             0.0                         0.0   \n",
       "4                             0.0                         0.0   \n",
       "...                           ...                         ...   \n",
       "14566                         0.0                         0.0   \n",
       "14567                        35.0                         1.0   \n",
       "14568                         0.0                         0.0   \n",
       "14569                         0.0                         0.0   \n",
       "14570                         0.0                         0.0   \n",
       "\n",
       "       0.000000000000000000e+00.10  0.000000000000000000e+00.11  \\\n",
       "0                              0.0                          0.0   \n",
       "1                              0.0                          0.0   \n",
       "2                              0.0                       2577.0   \n",
       "3                              0.0                          0.0   \n",
       "4                            266.0                         67.0   \n",
       "...                            ...                          ...   \n",
       "14566                          0.0                          0.0   \n",
       "14567                       1887.0                        406.0   \n",
       "14568                          0.0                          0.0   \n",
       "14569                          0.0                          0.0   \n",
       "14570                          0.0                        558.0   \n",
       "\n",
       "       0.000000000000000000e+00.12  0.000000000000000000e+00.13  \\\n",
       "0                              0.0                          0.0   \n",
       "1                              0.0                          0.0   \n",
       "2                           2180.0                       3170.0   \n",
       "3                              0.0                          0.0   \n",
       "4                              1.0                         26.0   \n",
       "...                            ...                          ...   \n",
       "14566                          0.0                          0.0   \n",
       "14567                         49.0                         35.0   \n",
       "14568                          0.0                          0.0   \n",
       "14569                        214.0                         31.0   \n",
       "14570                         18.0                         33.0   \n",
       "\n",
       "       0.000000000000000000e+00.14  0.000000000000000000e+00.15  \\\n",
       "0                            341.0                         20.0   \n",
       "1                              0.0                          2.0   \n",
       "2                            676.0                       1463.0   \n",
       "3                              0.0                          0.0   \n",
       "4                              2.0                       4442.0   \n",
       "...                            ...                          ...   \n",
       "14566                          0.0                          3.0   \n",
       "14567                          1.0                         22.0   \n",
       "14568                          0.0                          0.0   \n",
       "14569                          1.0                          2.0   \n",
       "14570                         26.0                          1.0   \n",
       "\n",
       "       0.000000000000000000e+00.16  0.000000000000000000e+00.17  \\\n",
       "0                            164.0                        884.0   \n",
       "1                             38.0                        193.0   \n",
       "2                            756.0                         19.0   \n",
       "3                              0.0                        255.0   \n",
       "4                             30.0                        154.0   \n",
       "...                            ...                          ...   \n",
       "14566                         11.0                        221.0   \n",
       "14567                         72.0                       1334.0   \n",
       "14568                          0.0                        293.0   \n",
       "14569                        101.0                         32.0   \n",
       "14570                        622.0                        389.0   \n",
       "\n",
       "       0.000000000000000000e+00.18  4.200000000000000000e+01  \n",
       "0                             80.0                    4441.0  \n",
       "1                             18.0                      84.0  \n",
       "2                            307.0                    1926.0  \n",
       "3                             30.0                     154.0  \n",
       "4                             13.0                    1366.0  \n",
       "...                            ...                       ...  \n",
       "14566                          1.0                     261.0  \n",
       "14567                         10.0                     687.0  \n",
       "14568                        278.0                      25.0  \n",
       "14569                        752.0                    1667.0  \n",
       "14570                         64.0                       1.0  \n",
       "\n",
       "[14571 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = pd.read_csv('review.csv')\n",
    "lab = pd.read_csv('label.csv')\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29d633172c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='airline_sentiment', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(11656, 20) \n",
      "Validation set: \t(1457, 20) \n",
      "Test set: \t\t(1458, 20)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.80\n",
    "split_idx = int(len(rev)*split_frac)\n",
    "train_x, remaining_x = rev[:split_idx], rev[split_idx:]\n",
    "train_y, remaining_y = lab[:split_idx], lab[split_idx:]\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 128)           1313536   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,445,249\n",
      "Trainable params: 1,445,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(10262, 128,input_length=20))\n",
    "model_1.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11656 samples, validate on 1457 samples\n",
      "Epoch 1/15\n",
      "11656/11656 [==============================] - 22s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.3987 - val_accuracy: 0.8126\n",
      "Epoch 2/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.3132 - accuracy: 0.8657 - val_loss: 0.4370 - val_accuracy: 0.8003\n",
      "Epoch 3/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.2432 - accuracy: 0.9019 - val_loss: 0.4639 - val_accuracy: 0.8023\n",
      "Epoch 4/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.1911 - accuracy: 0.9219 - val_loss: 0.5250 - val_accuracy: 0.7879\n",
      "Epoch 5/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.1580 - accuracy: 0.9365 - val_loss: 0.5847 - val_accuracy: 0.7886\n",
      "Epoch 6/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.1294 - accuracy: 0.9477 - val_loss: 0.6871 - val_accuracy: 0.7893\n",
      "Epoch 7/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.1127 - accuracy: 0.9557 - val_loss: 0.6593 - val_accuracy: 0.7914\n",
      "Epoch 8/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.1013 - accuracy: 0.9603 - val_loss: 0.7434 - val_accuracy: 0.7879\n",
      "Epoch 9/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.0901 - accuracy: 0.9620 - val_loss: 0.8303 - val_accuracy: 0.7927\n",
      "Epoch 10/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.0816 - accuracy: 0.9658 - val_loss: 0.8874 - val_accuracy: 0.7845\n",
      "Epoch 11/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.0705 - accuracy: 0.9710 - val_loss: 0.9796 - val_accuracy: 0.7865\n",
      "Epoch 12/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.0689 - accuracy: 0.9719 - val_loss: 1.0625 - val_accuracy: 0.7824\n",
      "Epoch 13/15\n",
      "11656/11656 [==============================] - 21s 2ms/step - loss: 0.0559 - accuracy: 0.9774 - val_loss: 1.0560 - val_accuracy: 0.7872\n",
      "Epoch 14/15\n",
      "11656/11656 [==============================] - 22s 2ms/step - loss: 0.0544 - accuracy: 0.9786 - val_loss: 1.1359 - val_accuracy: 0.7838\n",
      "Epoch 15/15\n",
      "11656/11656 [==============================] - 22s 2ms/step - loss: 0.0515 - accuracy: 0.9795 - val_loss: 1.1748 - val_accuracy: 0.7797\n",
      "1458/1458 [==============================] - 1s 462us/step\n",
      "Score :  0.8822336673368643\n",
      "Accuracy :  0.8175582885742188\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(train_x, train_y,\n",
    "          batch_size=30,\n",
    "          epochs=15,\n",
    "          validation_data=(val_x, val_y))\n",
    "score, acc = model_1.evaluate(test_x,test_y,batch_size=30)\n",
    "print(\"Score : \",score)\n",
    "print(\"Accuracy : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(10262, 128,input_length=20))\n",
    "model_2.add(LSTM(128,return_sequences=True))\n",
    "model_2.add(LSTM(128,return_sequences=False))\n",
    "model_2.add(Dropout(0.5))\n",
    "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_2.add(Dense(1, activation='relu'))\n",
    "model_2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 128)           1313536   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 20, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,576,833\n",
      "Trainable params: 1,576,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11656 samples, validate on 1457 samples\n",
      "Epoch 1/15\n",
      "11656/11656 [==============================] - 34s 3ms/step - loss: 0.6271 - accuracy: 0.7190 - val_loss: 0.5292 - val_accuracy: 0.7570\n",
      "Epoch 2/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.4771 - accuracy: 0.8048 - val_loss: 0.6867 - val_accuracy: 0.7852\n",
      "Epoch 3/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.3690 - accuracy: 0.8206 - val_loss: 0.8267 - val_accuracy: 0.7666\n",
      "Epoch 4/15\n",
      "11656/11656 [==============================] - 34s 3ms/step - loss: 0.3991 - accuracy: 0.7963 - val_loss: 0.8731 - val_accuracy: 0.7364\n",
      "Epoch 5/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.3558 - accuracy: 0.8122 - val_loss: 1.0996 - val_accuracy: 0.7234\n",
      "Epoch 6/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.2668 - accuracy: 0.7786 - val_loss: 1.0915 - val_accuracy: 0.7097\n",
      "Epoch 7/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.2786 - accuracy: 0.7937 - val_loss: 1.4584 - val_accuracy: 0.7076\n",
      "Epoch 8/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.2652 - accuracy: 0.7990 - val_loss: 2.4513 - val_accuracy: 0.5072\n",
      "Epoch 9/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.2576 - accuracy: 0.7740 - val_loss: 1.6500 - val_accuracy: 0.7165\n",
      "Epoch 10/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.2302 - accuracy: 0.7369 - val_loss: 1.7450 - val_accuracy: 0.6863\n",
      "Epoch 11/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.2014 - accuracy: 0.7554 - val_loss: 1.8391 - val_accuracy: 0.6493\n",
      "Epoch 12/15\n",
      "11656/11656 [==============================] - 33s 3ms/step - loss: 0.2109 - accuracy: 0.7655 - val_loss: 1.6026 - val_accuracy: 0.6877\n",
      "Epoch 13/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.1791 - accuracy: 0.7209 - val_loss: 1.9040 - val_accuracy: 0.6905\n",
      "Epoch 14/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.2128 - accuracy: 0.7410 - val_loss: 1.8398 - val_accuracy: 0.6589\n",
      "Epoch 15/15\n",
      "11656/11656 [==============================] - 32s 3ms/step - loss: 0.1737 - accuracy: 0.7092 - val_loss: 2.0325 - val_accuracy: 0.6479\n",
      "1458/1458 [==============================] - 1s 518us/step\n",
      "Score :  1.713205769075533\n",
      "Accuracy :  0.706447184085846\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "model_2.fit(train_x, train_y,\n",
    "          batch_size=30,\n",
    "          epochs=15,\n",
    "          validation_data=(val_x, val_y)\n",
    "      #    callbacks=[checkpoint], \n",
    "       #   verbose=False\n",
    "         )\n",
    "score, acc = model_2.evaluate(test_x,test_y,batch_size=30)\n",
    "print(\"Score : \",score)\n",
    "print(\"Accuracy : \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
